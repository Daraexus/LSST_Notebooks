{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obligatory import for the notebook sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.table as afwTable\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lsst.daf.persistence as dafPersist\n",
    "import re\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File containing the Mjd dictionary. Directory definition (depending wich set of data is going to be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_distance(src1, src2):\n",
    "    ra, dec = src1['ra'], src1['dec']\n",
    "    ra2, dec2 = src2['ra'], src2['dec']\n",
    "            \n",
    "    return np.sqrt((float(ra)-float(ra2))**2+(float(dec)-float(dec2))**2)/3.14159*180*3600\n",
    "\n",
    "\n",
    "def threshold_light_curves(light_curves, threshold):\n",
    "    t_light_curves = [lc for lc in light_curves if len(lc) >= threshold]\n",
    "    return t_light_curves\n",
    "\n",
    "def build_light_curve_from_snls_file(data, c):\n",
    "\n",
    "    bandpasses = ['r']\n",
    "\n",
    "\n",
    "    lightcurve = {}\n",
    "    lightcurve['bandpass'] = []\n",
    "    lightcurve['mjd'] = []\n",
    "    lightcurve['ra'] = []\n",
    "    lightcurve['dec'] = []\n",
    "    lightcurve['flux'] = []\n",
    "    lightcurve['flux_error'] = []\n",
    "    lightcurve['zp'] = []\n",
    "    lightcurve['zpsys'] = []\n",
    "\n",
    "\n",
    "    for mjd, flux, error in data:\n",
    "\n",
    "        #print 'yep',visit\n",
    "        lightcurve['bandpass'].append(str('sdss' + bandpasses[0]))\n",
    "        lightcurve['mjd'].append(float(mjd))\n",
    "        lightcurve['ra'].append(c.ra.radian)\n",
    "        lightcurve['dec'].append(c.dec.radian)\n",
    "        lightcurve['flux'].append(float(flux))\n",
    "        lightcurve['flux_error'].append(float(error))\n",
    "        #lightcurve['flux'].append(src['base_CircularApertureFlux_12_0_flux'])\n",
    "        #lightcurve['flux_error'].append(src['base_CircularApertureFlux_12_0_fluxSigma'])\n",
    "        lightcurve['zp'].append(25.0)\n",
    "        lightcurve['zpsys'].append('ab')\n",
    "\n",
    "    lc = Table(data=lightcurve)\n",
    "    return lc\n",
    "\n",
    "def build_lightcurve(source_list):\n",
    "    \"\"\"\n",
    "    Assemble a light curve data table from available files.\n",
    "    \"\"\"\n",
    "\n",
    "    bandpasses = ['r']\n",
    "\n",
    "\n",
    "    lightcurve = {}\n",
    "    lightcurve['classification'] = []\n",
    "    lightcurve['bandpass'] = []\n",
    "    lightcurve['mjd'] = []\n",
    "    lightcurve['ra'] = []\n",
    "    lightcurve['dec'] = []\n",
    "    lightcurve['flux'] = []\n",
    "    lightcurve['flux_error'] = []\n",
    "    lightcurve['zp'] = []\n",
    "    lightcurve['zpsys'] = []\n",
    "\n",
    "\n",
    "    for visit, src in source_list:\n",
    "\n",
    "        #print 'yep',visit\n",
    "        lightcurve['classification'].append(src['classification_dipole'])\n",
    "        lightcurve['bandpass'].append(str('sdss' + bandpasses[0]))\n",
    "        lightcurve['mjd'].append(mjds[str(visit)])\n",
    "        lightcurve['ra'].append(src['coord_ra'])\n",
    "        lightcurve['dec'].append(src['coord_dec'])\n",
    "        lightcurve['flux'].append(src['base_CircularApertureFlux_4_5_flux'])\n",
    "        lightcurve['flux_error'].append(src['base_CircularApertureFlux_4_5_fluxSigma'])\n",
    "        #lightcurve['flux'].append(src['base_CircularApertureFlux_12_0_flux'])\n",
    "        #lightcurve['flux_error'].append(src['base_CircularApertureFlux_12_0_fluxSigma'])\n",
    "        lightcurve['zp'].append(25.0)\n",
    "        lightcurve['zpsys'].append('ab')\n",
    "    lightcurve = Table(data=lightcurve)\n",
    "    return lightcurve\n",
    "\n",
    "\n",
    "def mean_lc_flux(lc2):\n",
    "\n",
    "    mjds = []\n",
    "    m_fluxes = []\n",
    "    m_error = []\n",
    "    s_error = []\n",
    "    i = 0\n",
    "    while i < len(lc2['mjd']):\n",
    "        mjd = lc2['mjd'][i]\n",
    "        j = i+1\n",
    "        mjds.append(int(mjd))\n",
    "        m_fluxes.append(lc2['flux'][i]*lc2['flux_error'][i])\n",
    "        m_error.append(lc2['flux_error'][i])\n",
    "        s_error.append(lc2['flux_error'][i]**2)\n",
    "        total = 1.\n",
    "       \n",
    "        while j<len(lc2['mjd']) and int(lc2['mjd'][j]) == int(mjd):\n",
    "\n",
    "            m_fluxes[-1]+= lc2['flux'][j]*lc2['flux_error'][j]\n",
    "            \n",
    "\n",
    "                \n",
    "            m_error[-1] += lc2['flux_error'][j]\n",
    "            s_error[-1] += (lc2['flux_error'][j]**2)\n",
    "            #mjds[-1] += int(lc2['mjd'][j])\n",
    "            total+=1\n",
    "            j+=1\n",
    "            \n",
    "       \n",
    "        m_fluxes[-1] = np.divide(m_fluxes[-1], m_error[-1] )\n",
    "        m_error[-1] = np.divide(np.sqrt(s_error[-1]), total)\n",
    "        i = j\n",
    "\n",
    "    return mjds, m_fluxes, m_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light curves from SNLS are read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the butler instance from the main data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[836493 836494 836495 836496 836497 836498 837002 837003 837004 837005\n",
      " 837006 837007 837008 838853 838854 838855 838857 838864 838865 838866\n",
      " 838867 838868 839308 839309 839310 839311 839312 844210 844211 844212\n",
      " 844213 844214 844230 844489 844490 844491 844492 844493 844494 844495\n",
      " 844496 844497 844498 844514 844515 844516 844517 844518 844845 844846\n",
      " 844847 844848 844849 845345 845346 845347 845348 845349 849373 849374\n",
      " 849375 849376 849377 849685 849686 849687 849688 849689 850177 850178\n",
      " 850179 850180 850181 850586 850587 850588 850589 850590 851057 851058\n",
      " 851059 851060 851061 852890 852891 852892 852893 852894 853232 853233\n",
      " 853234 853235 853236 853539 853540 853541 853542 853543 853727 853728\n",
      " 853729 853730 853731 858537 858538 858539 858540 858541 859608 859609\n",
      " 859610 859611 859612 860146 860147 860148 860149 860150]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATADIR=\"/renoir_data_02/jpreyes/lsst_data/CFHTLS_master/\"\n",
    "\n",
    "butler = dafPersist.Butler(DATADIR+\"/output\")\n",
    "visits = butler.queryMetadata(\"deepDiff_differenceExp\", format=['visit'],dataId={'filter':'r'})\n",
    "visits = np.array(visits)\n",
    "mask = (visits >= 836493) & (visits <= 860150)\n",
    "visits =  visits[mask]\n",
    "print visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "directory = \"catalogs/4sigma/\"\n",
    "d_directory = \"catalogs/4sigma_i/\"\n",
    "\n",
    "files = os.listdir(directory)\n",
    "\n",
    "y, n = 0,0\n",
    "\n",
    "for f in files:\n",
    "    visit = int(f.split(\"-\")[0])\n",
    "    ccd = int(f.split(\"-\")[-1].split(\".\")[0])\n",
    "    if butler.datasetExists(\"deepDiff_differenceExp\", {'visit': visit , 'filter':\"i\" , 'ccd':ccd}):\n",
    "        y+=1\n",
    "    else:\n",
    "        n+=1\n",
    "        \n",
    "print y,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = \"catalogs/4sigma/\"\n",
    "d_directory = \"catalogs/4sigma_i/\"\n",
    "files = os.listdir(directory)\n",
    "for f in files:\n",
    "    visit = int(f.split(\"-\")[0])\n",
    "    if int(visit) not in visits:\n",
    "       \n",
    "        os.rename(directory+f, d_directory+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
